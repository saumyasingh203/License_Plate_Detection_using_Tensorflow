{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR_detected_license_plate_using_Tensorflow\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yo_make_the_conversion(img_data, count):\n",
    "    img = img_data\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    path_png='png_tesseract'\n",
    "    count += 1\n",
    "    filename = os.path.join(path_png,'image{}.png'.format(count))\n",
    "    cv2.imwrite(filename, gray)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_array(tex):\n",
    "    side=tex\n",
    "    az='ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'\n",
    "    i=0\n",
    "    yo=len(az)\n",
    "    txt=''\n",
    "    for i in range(0,yo):\n",
    "        if side==az[i]:\n",
    "            txt=az[i]\n",
    "            break\n",
    "    return txt   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_rectify_plate_characters(text):\n",
    "    tex = text\n",
    "    out1=[]\n",
    "    size=len(tex)\n",
    "    for i in range(0,size):\n",
    "      if tex[i]==check_array(tex[i]):\n",
    "        out1.append(tex[i])\n",
    "    yup=''.join(str(e) for e in out1)    \n",
    "    return yup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'number_plate'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/graph-200000/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('training', 'object-detection.pbtxt')\n",
    "NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.compat.v1.GraphDef()\n",
    "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.compat.v1.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = 'png_tesseract/test_ram'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.JPEG'.format(i)) for i in range(0,17) ]\n",
    "IMAGE_SIZE = (12, 8)\n",
    "TEST_DHARUN=os.path.join('number_plate')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARCTER RECOGNITION :  HR696969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1ad6773a6031>:48: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARCTER RECOGNITION :  TN07BU5427\n",
      "CHARCTER RECOGNITION :  HR26DK0830\n",
      "CHARCTER RECOGNITION :  DL7CN5617\n",
      "CHARCTER RECOGNITION :  DL3CAY9324\n",
      "CHARCTER RECOGNITION :  \n",
      "CHARCTER RECOGNITION :  GJW115A1138\n",
      "CHARCTER RECOGNITION :  DL12CG6648\n",
      "CHARCTER RECOGNITION :  UP14CP6748\n",
      "CHARCTER RECOGNITION :  HR26BR9044\n",
      "CHARCTER RECOGNITION :  HH20CS9817\n",
      "CHARCTER RECOGNITION :  TN38MG6162\n",
      "CHARCTER RECOGNITION :  TN38BY4191\n",
      "CHARCTER RECOGNITION :  DL3CAY2231\n",
      "CHARCTER RECOGNITION :  DL3CBF3907\n",
      "CHARCTER RECOGNITION :  \n",
      "CHARCTER RECOGNITION :  \n"
     ]
    }
   ],
   "source": [
    "with detection_graph.as_default():\n",
    "  with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    for image_path in TEST_IMAGE_PATHS:\n",
    "      image = Image.open(image_path) \n",
    "      image_np = cv2.imread(image_path,1)\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "      (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "      ymin = boxes[0,0,0]\n",
    "      xmin = boxes[0,0,1]\n",
    "      ymax = boxes[0,0,2]\n",
    "      xmax = boxes[0,0,3]\n",
    "      (im_width, im_height) = image.size\n",
    "      (xminn, xmaxx, yminn, ymaxx) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "      cropped_image = tf.image.crop_to_bounding_box(image_np, int(yminn), int(xminn),int(ymaxx - yminn), int(xmaxx - xminn))\n",
    "      img_data = sess.run(cropped_image)\n",
    "      count = 0\n",
    "      \n",
    "      config = ('-l eng --oem 1 --psm 3')\n",
    "      filename = yo_make_the_conversion(img_data, count)\n",
    "\n",
    "      pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR'\n",
    "      pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "      text = pytesseract.image_to_string(img_data,config=config)\n",
    "      print('CHARCTER RECOGNITION : ',catch_rectify_plate_characters(text))\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          np.squeeze(boxes),\n",
    "          np.squeeze(classes).astype(np.int32),\n",
    "          np.squeeze(scores),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=5)\n",
    "      \n",
    "      \n",
    "      plt.figure(figsize=IMAGE_SIZE)\n",
    "      plt.subplot(1,2,1)\n",
    "      plt.imshow(image)\n",
    "      plt.subplot(1,2,2)\n",
    "      plt.imshow(img_data)\n",
    "      plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp(image_path):\n",
    "    with detection_graph.as_default():\n",
    "          with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "\n",
    "            image = Image.open(image_path) \n",
    "            image_np = cv2.imread(image_path,1)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "            ymin = boxes[0,0,0]\n",
    "            xmin = boxes[0,0,1]\n",
    "            ymax = boxes[0,0,2]\n",
    "            xmax = boxes[0,0,3]\n",
    "            (im_width, im_height) = image.size\n",
    "            (xminn, xmaxx, yminn, ymaxx) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "            cropped_image = tf.image.crop_to_bounding_box(image_np, int(yminn), int(xminn),int(ymaxx - yminn), int(xmaxx - xminn))\n",
    "            img_data = sess.run(cropped_image)\n",
    "            count = 0\n",
    "\n",
    "            config = ('-l eng --oem 1 --psm 3')\n",
    "            filename = yo_make_the_conversion(img_data, count)\n",
    "\n",
    "            pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR'\n",
    "            pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "            text = pytesseract.image_to_string(img_data,config=config)\n",
    "            \n",
    "            result = catch_rectify_plate_characters(text)\n",
    "#             messagebox.showinfo('CHARCTER RECOGNITION : ',result)\n",
    "            return (result,filename)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk,Button,Text,Canvas,PhotoImage,Label\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import messagebox\n",
    "import requests\n",
    "\n",
    "URL = \"http://localhost:5000/list\"\n",
    "\n",
    "\n",
    "\n",
    "tkWindow = Tk()  \n",
    "tkWindow.geometry('400x150')  \n",
    "tkWindow.title('PythonExamples.org - Tkinter Example')\n",
    "tkWindow.configure(background='lightblue')\n",
    "\n",
    "def showMsg():  \n",
    "    tkResult = Tk()  \n",
    "    tkResult.geometry('400x150')  \n",
    "    tkResult.title('Details of the Detected License Plate')\n",
    "    tkResult.configure(background='lightgreen')\n",
    "    var = inputtxt.get(1.0, \"end-1c\")\n",
    "    result,filename = temp(var)\n",
    "    Label(tkResult, text=\"CHARCTER RECOGNITION OUTPUT\", font=('Caveat 15 bold')).pack(pady=20)\n",
    "    Label(tkResult, text=result, font=('Caveat 15 bold')).pack(pady=20)\n",
    "    PARAMS = {'x':result}\n",
    "    r = requests.get(url = URL, params = PARAMS)\n",
    "    print(r.text)\n",
    "    \n",
    "def showInputImg():\n",
    "#     path = \"png_tesseract/test_ram/image0.JPEG\"\n",
    "    pathToInput = inputtxt.get(1.0, \"end-1c\")\n",
    "    img= Image.open(pathToInput)\n",
    "    img=ImageTk.PhotoImage(img)\n",
    "    label= Label(tkWindow, image= img)\n",
    "    label.image= img\n",
    "    label.pack()\n",
    "    \n",
    "\n",
    "# png_tesseract/test_ram/image0.JPEG\n",
    "\n",
    "inputtxt = Text(tkWindow, height = 5, width = 20)\n",
    "inputtxt.pack()\n",
    "\n",
    "button = Button(tkWindow,\n",
    "text = 'Show uploaded Image',\n",
    "command = showInputImg)\n",
    "button.pack()  \n",
    "\n",
    "button = Button(tkWindow,\n",
    "text = 'Submit',\n",
    "command = showMsg)  \n",
    "button.pack()  \n",
    "\n",
    " \n",
    "  \n",
    "tkWindow.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    }
   ],
   "source": [
    "URL = \"http://localhost:5000/list\"\n",
    "PARAMS = {'x':\"result\"}\n",
    "r = requests.get(url = URL, params = PARAMS)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "png_tesseract/test_ram\\image0.JPEG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('HR696969',\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=551x455 at 0x153D77B61C0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "PATH_TO_TEST_IMAGES_DIR = 'png_tesseract/test_ram'\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.JPEG'.format(i)) for i in range(0,5) ]\n",
    "print(TEST_IMAGE_PATHS[0])\n",
    "temp(\"png_tesseract/test_ram/image0.JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-124-69f03e8b06cb>\", line 14, in showMsg\n",
      "    var = inputtxt.get(1.0, \"end-1c\")\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\lib\\tkinter\\__init__.py\", line 3711, in get\n",
      "    return self.tk.call(self._w, 'get', index1, index2)\n",
      "_tkinter.TclError: invalid command name \".!text\"\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "URL = \"http://localhost:5000/list\"\n",
    "\n",
    "\n",
    "#Create an instance of Tkinter frame\n",
    "win= Tk()\n",
    "win.configure(background='pink')\n",
    "\n",
    "def showMsg():  \n",
    "    var = inputtxt.get(1.0, \"end-1c\")\n",
    "    result = temp(var)\n",
    "    PARAMS = {'x':result}\n",
    "    r = requests.get(url = URL, params = PARAMS)\n",
    "    print(r.text)\n",
    "    \n",
    "    \n",
    "#Define the geometry\n",
    "win.geometry(\"750x350\")\n",
    "win.title(\"Image Gallery\")\n",
    "def select_file():\n",
    "   path= filedialog.askopenfilename(title=\"Select an Image\", filetype=(('image    files','*.jpeg'),('all files','*.*')))\n",
    "   img= Image.open(path)\n",
    "   img=ImageTk.PhotoImage(img)\n",
    "   label= Label(win, image= img)\n",
    "   label.image= img\n",
    "   label.pack()\n",
    "#Create a label and a Button to Open the dialog\n",
    "Label(win, text=\"Click the Button below to select an Image\", font=('Caveat 15 bold')).pack(pady=20)\n",
    "button= ttk.Button(win, text=\"Select to Open\", command= select_file)\n",
    "button.pack(ipadx=5, pady=15)\n",
    "button= ttk.Button(win, text=\"Get License Plate and Other Details\", command= showMsg)\n",
    "button.pack(ipadx=5, pady=15)\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk,Button,Text,Canvas,PhotoImage,Label\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import messagebox\n",
    "import requests\n",
    "\n",
    "URL = \"http://localhost:5000/list\"\n",
    "\n",
    "\n",
    "\n",
    "tkWindow = Tk()  \n",
    "tkWindow.geometry('400x150')  \n",
    "tkWindow.title('PythonExamples.org - Tkinter Example')\n",
    "tkWindow.configure(background='pink')\n",
    "\n",
    "def showMsg():  \n",
    "    var = inputtxt.get(1.0, \"end-1c\")\n",
    "    result = temp(var)\n",
    "    PARAMS = {'x':result}\n",
    "    r = requests.get(url = URL, params = PARAMS)\n",
    "    print(r.text)\n",
    "    \n",
    "def showInputImg():\n",
    "#     path = \"png_tesseract/test_ram/image0.JPEG\"\n",
    "    pathToInput = inputtxt.get(1.0, \"end-1c\")\n",
    "    img= Image.open(pathToInput)\n",
    "    img=ImageTk.PhotoImage(img)\n",
    "    label= Label(win, image= img)\n",
    "    \n",
    "\n",
    "# png_tesseract/test_ram/image0.JPEG\n",
    "\n",
    "inputtxt = Text(tkWindow, height = 5, width = 20)\n",
    "inputtxt.pack()\n",
    "\n",
    "button = Button(tkWindow,\n",
    "text = 'Show uploaded Image',\n",
    "command = showInputImg)\n",
    "button.pack()  \n",
    "\n",
    "button = Button(tkWindow,\n",
    "text = 'Submit',\n",
    "command = showMsg)  \n",
    "button.pack()  \n",
    "\n",
    " \n",
    "  \n",
    "tkWindow.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "\n",
    "class PokemonClass(object):\n",
    "\n",
    "    def __init__(self, master):\n",
    "        frame = Frame(master)\n",
    "        frame.pack()\n",
    "\n",
    "        self.WelcomeLabel = Label(root, text = \"Welcome! Pick your Pokemon!\", bg = \"Black\", fg = \"White\")\n",
    "        self.WelcomeLabel.pack(fill = X)\n",
    "\n",
    "        self.CharButton = Button(root, text = \"Charmander\", bg = \"RED\", fg = \"White\", command = CharClick)\n",
    "        self.CharButton.pack(side = LEFT, fill = X)\n",
    "\n",
    "        self.SquirtButton = Button(root, text = \"Squirtle\", bg = \"Blue\", fg = \"White\")\n",
    "        self.SquirtButton.pack(side = LEFT, fill = X)\n",
    "\n",
    "        self.BulbButton = Button(root, text = \"Bulbasaur\", bg = \"Dark Green\", fg = \"White\")\n",
    "        self.BulbButton.pack(side = LEFT, fill = X)\n",
    "\n",
    "    def CharClick():\n",
    "        print (\"You like Charmander!\")\n",
    "        CharPhoto = PhotoImage(file = \"Charmander.gif\")\n",
    "        ChLabel = Label(root, image = CharPhoto)\n",
    "        ChLabel.pack()\n",
    "\n",
    "\n",
    "k = PokemonClass(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
